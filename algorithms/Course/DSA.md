## Two approaches in DSP

* The first, popularized by Aho, Hopcroft, and Ullman and Cormen, Leiserson, Rivest, and Stein, concentrates on determining the growth of the worst-case performance of the algorithm (an “upper bound”). A prime goal in such analyses is to determine which algorithms are optimal in the sense that a matching “lower bound” can be proved on the worst-case performance of any algorithm for the same problem. We use the term theory of algorithms to refer to this type of analysis. 

* The second approach to the analysis of algorithms, popularized by Knuth, concentrates on precise characterizations of the best-case, worst-case, and average-case performance of algorithms, using a methodology that can be refined to produce increasingly precise answers when desired.


## DSA Notation

* The O-notation provides a way to express an upper bound
* The Ω-notation provides a way to express a lower bound (Omega)
* The Θ-notation provides a way to express matching upper and lower bounds


## Difference between Big O and Big Ω

* Big O is used to describe the worst case running time for an algorithm. 
* Big Ω notation, on the other hand, is used to describe the best case running time for a given algorithm.

## Logarithm bases

* lnN ≡ logeN == log(e)N (base e)
* lgN ≡ log2N


## Math references

* https://dlmf.nist.gov/
* https://oeis.org/
* https://mathworld.wolfram.com/topics/DiscreteMathematics.html
* https://math.stackexchange.com/
* https://math.stackexchange.com/questions/tagged/combinatorics?tab=Votes